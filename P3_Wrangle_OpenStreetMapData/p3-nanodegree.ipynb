{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data Wrangling with MongoDB\n",
    "\n",
    "Author: Hana AlMashari\n",
    "\n",
    "Date: June 3, 2017\n",
    "\n",
    "Open Street Map: Manchester, England, United Kingdom\n",
    "\n",
    "In this project I will show the process of audting by identifying the problems in the data ,then cleaning some of this problems,finally will write the data to JSON file and import it to MongoDB and run some queries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Why Manchester : \n",
    "\n",
    "I’ve chosen (manchester_england) Data set since I'm planning to travel to it in my next vacation.So I found it good idea to explore the places and street and many things through this project.\n",
    "\n",
    "reference:(https://mapzen.com/data/metro-extracts/metro/manchester_england/101913963/Manchester/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Problems Encountered in the Data:\n",
    "\n",
    "#### Problems in phone numbers attribut:\n",
    "\n",
    "- Phone number written differently with spaces.\n",
    "- There's Special characters and letters.\n",
    "\n",
    "        <tag k=\"phone\" v=\"+441612366222\"/>\n",
    "        <tag k=\"phone\" v=\"0161 839 9035\"/>\n",
    "        <tag k=\"phone\" v=\"01606 46666\"/>\n",
    "\n",
    "#### Problems in street attribute ( addr:street ):\n",
    "- Some street names has special characters.\n",
    "- Street types (rd , road should be writtend in the same way)\n",
    "- Street type like Str in the beggining of the street name instead of the end like the blew: \n",
    "\t\t<tag k=\"addr:street\" v=\"St Paul’s Place\"/>\n",
    "    \t<tag k=\"addr:street\" v=\"St Mary&#39;s Road\"/>\n",
    "        \n",
    "#### Problems in postcode attribut (addr:postcode):\n",
    "When the city is Manchester the post code has the prefix M , and the belows post code are out of the range:\n",
    "\n",
    "\t\t<tag k=\"addr:postcode\" v=\"SK23 7LP\"/>\n",
    "\t\t<tag k=\"addr:postcode\" v=\"SK9 3PA\"/>\n",
    "\t\t<tag k=\"addr:postcode\" v=\"SK9 5LR\"/>\n",
    "\t\t<tag k=\"addr:postcode\" v=\"SK9 1PZ\"/>\n",
    "\t\t<tag k=\"addr:postcode\" v=\"SK9 7JT\"/>\n",
    "  \n",
    "#### General problem :\n",
    "- There're data not in city Manchester\n",
    "        <tag k=\"addr:city\" v=\"Manchester\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.13 |Anaconda custom (x86_64)| (default, Dec 20 2016, 23:05:08) \n",
      "[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]\n",
      "sys.version_info(major=2, minor=7, micro=13, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "#Importing \n",
    "import sys\n",
    "import pprint\n",
    "print(sys.version)#python version \n",
    "print(sys.version_info)\n",
    "#---------------------------------\n",
    "import xml.etree.ElementTree as ET #ET.iterparse(filename):\n",
    "from collections import defaultdict #using defaultdict(int)\n",
    "import re\n",
    "import os\n",
    "import xml.etree.cElementTree as ET\n",
    "import codecs\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Upload the file\n",
    "OSM_FILE = \"/Users/hana/Desktop/datascience/manchester_england.osm\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data Overview:\n",
    "\n",
    "Let's take an overviw of the file containing the data we're going to wrangle.In the below output is the size of the data which seems quit big one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357820941"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Return the size, in bytes,\n",
    "os.path.getsize('/Users/hana/Desktop/datascience/manchester_england.osm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "When Changing the unit form bytes to MB is about 357.8 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In order to Audit the DataSet we need to know overview of the Data by counting the number of unique element types in the OSM_FILE.Bacicaly we counts number of tags in the osm_file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounds': 1,\n",
      " 'member': 31102,\n",
      " 'nd': 1981674,\n",
      " 'node': 1603430,\n",
      " 'osm': 1,\n",
      " 'relation': 2426,\n",
      " 'tag': 875731,\n",
      " 'way': 224173}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%writefile mapparser.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import pprint\n",
    "\n",
    "#count the tags in a given file name \n",
    "def count_tags(filename):\n",
    "    tags = {}\n",
    "    for ev,elem in ET.iterparse(filename):\n",
    "        tag = elem.tag\n",
    "        if tag not in tags.keys():\n",
    "            tags[tag] = 1\n",
    "        else:\n",
    "            tags[tag]+=1\n",
    "    return tags\n",
    "\n",
    "def test():\n",
    "\n",
    "    tags = count_tags(OSM_FILE)\n",
    "    pprint.pprint(tags)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Auditing the Data:\n",
    "In auditing we need to \n",
    "- List the issues and \n",
    "- List expected value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In the below functions we go into tags and see the counts of the following cases:\n",
    "- \"lower\":Tags that contain only lowercase letters and are valid.\n",
    "- \"lower_colon\": Valid tags with a colon in their names.\n",
    "- \"problemchars\": Tags with problematic characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 651974, 'lower_colon': 101387, 'other': 122367, 'problemchars': 3}\n"
     ]
    }
   ],
   "source": [
    "#Before you process the data and add it into your database, we have to check the\n",
    "#\"k\" value for each \"<tag>\" and see if there are any potential problems.\n",
    "#Here I have built three regular expressions to check for certain patterns\n",
    "#in the tags.\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        for tag in element.iter('tag'):\n",
    "            k = tag.get('k')\n",
    "            if lower.search(k):\n",
    "                keys['lower'] += 1\n",
    "            elif lower_colon.search(k):\n",
    "                keys['lower_colon'] += 1\n",
    "            elif problemchars.search(k):\n",
    "                keys['problemchars'] += 1\n",
    "            else:\n",
    "                keys['other'] += 1\n",
    "        \n",
    "    return keys\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    \n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys\n",
    "\n",
    "keys = process_map(OSM_FILE)\n",
    "pprint.pprint(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, let's see the number of users contributed to the \"manchester_england\" map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2155"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_map(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        for e in element:\n",
    "            if 'uid' in e.attrib:\n",
    "                users.add(e.attrib['uid'])\n",
    "\n",
    "    return users\n",
    "\n",
    "users = process_map(OSM_FILE)\n",
    "len(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "I will be focusing on auditing and cleaning the following attributes:\n",
    "\n",
    "\n",
    "1. Street names\n",
    "2. Phonenumbers\n",
    "\n",
    "In cleaning the street names ,we looped through the Street names and by going through the values i have maintan the expected list values of street types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\",\"Cross\",\"Village\",\"Fold\",\n",
    "            \"Trail\", \"Parkway\", \"Commons\" ,\"West\" , \"East\" , \"Way\" , 'South','Estate' , \"Croft\" , \"Gate\",\"Walk\",\"North\",\"Terrace\",\n",
    "            'Walk' ,'Hill','Grove', 'Mews','Gardens','Park','Centre','Brow','Chase','Arcade','Close','Crescent' ,'Green',\n",
    "           \"Parade\" ,\"Quay\",\"Grange\",\"House\",\"Knowle\",\"View\" ,\"Mall\" ,\"Quays\" ,\"Meadow\" ,\"End\"]\n",
    "\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"street\": \"Street\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"avenue\" : \"Avenue\",\n",
    "            \"Rd.\" : \"Road\",\n",
    "            \"road\": \"Road\",\n",
    "            \"Rd\": \"Road\",\n",
    "            \"Gates\":\"Gate\",\n",
    "            \"square\" :\"Square\",\n",
    "            \"east\":\"East\",\n",
    "            \"Meadows\" : \"Meadow\",\n",
    "            \"Cottages\":\"Cottage\",\n",
    "            \"Ends\":\"End\",\n",
    "            \"Orchards\": \"Orchard\",\n",
    "            \"Heyes\": \"Hey\"\n",
    "            }\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "\n",
    "    return street_types\n",
    "\n",
    "\n",
    "st_types = audit(OSM_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In auditing the street types.\n",
    "\n",
    "* Case#1 : I added the street types that's in the file into the expected list.\n",
    "* Case#2 : Unify the types written in different types like the below: \n",
    "For the road , Rd i'm going to unify it to be Road  \n",
    "For avenue, Ave ==> Avenue \n",
    "Square , sq ==> Square \n",
    "* Case#3 :\n",
    "\n",
    "ّFor the street type with 's' at the end I unify the type to be single \n",
    "like below \n",
    "             'Meadow': {'Round Meadow'},\n",
    "             'Meadows': {'High Meadows'},\n",
    "so all will be \"Meadow\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pink => Pink\n",
      "Guywood Cottages => Guywood Cottage\n",
      "Rookery Cottages => Rookery Cottage\n",
      "Wharf Cottages => Wharf Cottage\n",
      "Shudehill => Shudehill\n",
      "Kingsway => Kingsway\n",
      "Burton Rd => Burton Road\n",
      "Mosley Rd => Mosley Road\n",
      "Stockport Rd => Streetockport Rd\n",
      "Wilmslow Rd => Wilmslow Road\n",
      "Churchfields => Churchfields\n",
      "Deangate => Deangate\n",
      "Dolefield => Dolefield\n",
      "Alderley Lodge => Alderley Lodge\n"
     ]
    }
   ],
   "source": [
    "def update_name(name, mapping):\n",
    "     sorted_keys = sorted(mapping.keys(), key=len, reverse=True)\n",
    "     for abbrv in sorted_keys:\n",
    "         if(abbrv in name):\n",
    "             name.rstrip() #removing spaces at the end of the street type\n",
    "             return name.replace(abbrv, mapping[abbrv])\n",
    "     return name\n",
    "\n",
    "\n",
    "def Run():\n",
    "    count = 0\n",
    "    for st_type, ways in st_types.iteritems():\n",
    "        count +=1\n",
    "        if count ==10:\n",
    "            break\n",
    "        for name in ways:\n",
    "            better_name = update_name(name, mapping)\n",
    "            print name,\"=>\", better_name\n",
    "\n",
    "Run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's see how different patteren phone number wrriten in dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def is_phone(elem):\n",
    "    return (elem.attrib['k'] == \"phone\")\n",
    "\n",
    "def is_city(elem): # needed if i will chek manchester\n",
    "    return (elem.attrib['k'] == \"addr:city\")\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    phone_types = []\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_phone(tag):\n",
    "                    phone_types.append(tag.attrib['v'])\n",
    "\n",
    "    return phone_types\n",
    "\n",
    "phones = audit(OSM_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "After checking the phone number i have notice that there are spaces and special characters in the phone number.\n",
    "Let's update the phone number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def update_phone (phonenumber):\n",
    "    phone_r = phonenumber.strip()\n",
    "    phone_s = phone_r.replace(\" \", \"\")\n",
    "    if phone_s[0] == \"+\":\n",
    "        phone_s = phone_s[2:]\n",
    "        phone_s = re.sub('[^a-zA-Z0-9-_*.]', '', phone_s) #replace special character with \"\" to remove it\n",
    "    return phone_s\n",
    "    \n",
    "def Run():\n",
    "    for phone in phones:\n",
    "        ph = update_phone(phone)\n",
    "        print phone ,\"=>\",ph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preparing for MongoDB \n",
    "In order to prepare for MongoDB we need first to convert the file To JSON format keeping the original file without modification.\n",
    "The structure of the data would be like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Form this format:\n",
    "\n",
    "    <node id=\"27169437\" lat=\"53.3930029\" lon=\"-2.2350969\" version=\"3\" timestamp=\"2017-01-20T23:17:54Z\" changeset=\"45341398\" uid=\"334129\" user=\"murble\">\n",
    "\t\t<tag k=\"addr:city\" v=\"Stockport\"/>\n",
    "\t\t<tag k=\"addr:housenumber\" v=\"144\"/>\n",
    "\t\t<tag k=\"addr:postcode\" v=\"SK8 4AB\"/>\n",
    "\t\t<tag k=\"addr:street\" v=\"Gatley Road\"/>\n",
    "\t\t<tag k=\"amenity\" v=\"pub\"/>\n",
    "\t\t<tag k=\"fhrs:id\" v=\"144880\"/>\n",
    "\t\t<tag k=\"name\" v=\"The Horse and Farrier\"/>\n",
    "\t\t<tag k=\"smoking\" v=\"outside\"/>\n",
    "\t</node>\n",
    "---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "To this \n",
    "\n",
    "\n",
    "{\n",
    "    \"id\": \"27169437\",\n",
    "    \"type: \"node\",\n",
    "    \"visible\":\"true\",\n",
    "    \"created\": {\n",
    "                  \"version\":\"3\",\n",
    "                  \"changeset\":\"45341398\",\n",
    "                  \"timestamp\":\"2017-01-20T23:17:54Z\",\n",
    "                  \"user\":\"murble\",\n",
    "                  \"uid\":\"334129\"\n",
    "               },\n",
    "    \"pos\": [53.3930029, -2.2350969],\n",
    "    \"address\": {  \n",
    "                  \"housenumber\": \"144\",\n",
    "                  \"postcode\": \"SK8 4AB\",\n",
    "                  \"street\": \"Gatley Road\"\n",
    "                  \"city\"  : \"Stockport\"\n",
    "               },\n",
    "    \"amenity\": \"pub\",\n",
    "    \"name\": \"The Horse and Farrier\",\n",
    "    \"phone\": \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The transform will follow these rules in josn:\n",
    "* Process only 2 types of top level tags: node and way\n",
    "* All attributes of node and way should be turned into regular key/value pairs.\n",
    "* (created key) has  version, changeset, timestamp, user, uid\n",
    "* latitude and longitude attributes should be added to a pos array\n",
    "* Ignore second level tag \"k\" value that contains problemtic characters.\n",
    "* scond level tag that starts with addr: will be added to address dic\n",
    "* any tag contains \":\" will deal with it like any other tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prosses to josn file \n",
    "CREATED = [\"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "\n",
    "def shape_element(element):\n",
    "    node = {}    \n",
    "    if element.tag == \"node\" or element.tag == \"way\" :\n",
    "        node['type'] = element.tag\n",
    "        \n",
    "        # Parse attributes josn\n",
    "        for attrib in element.attrib:\n",
    "\n",
    "            # Creation Data\n",
    "            if attrib in CREATED:\n",
    "                if 'created' not in node:\n",
    "                    node['created'] = {}\n",
    "                if attrib == 'timestamp':\n",
    "                    node['created'][attrib] = datetime.strptime(element.attrib[attrib], '%Y-%m-%dT%H:%M:%SZ')\n",
    "                else:\n",
    "                    node['created'][attrib] = element.get(attrib)\n",
    "\n",
    "            # Parse location (Latitude and Longitude )\n",
    "            if attrib in ['lat', 'lon']:\n",
    "                lat = float(element.attrib.get('lat'))\n",
    "                lon = float(element.attrib.get('lon'))\n",
    "                node['pos'] = [lat, lon]\n",
    "\n",
    "            # Parse the rest of attributes\n",
    "            else:\n",
    "                node[attrib] = element.attrib.get(attrib)\n",
    "            \n",
    "        # Process tags\n",
    "        for tag in element.iter('tag'):\n",
    "            key   = tag.attrib['k']\n",
    "            value = tag.attrib['v']\n",
    "            if not problemchars.search(key):\n",
    "                #applying the phone cleaning\n",
    "                if key == \"phone\":\n",
    "                    updated_phone = update_phone(tag.attrib['v'])\n",
    "                    node['phone'] = updated_phone\n",
    "                # addr Tags with :\n",
    "                if lower_colon.search(key) and key.find('addr') == 0:\n",
    "                    if 'address' not in node:\n",
    "                        node['address'] = {}\n",
    "                    sub_attr = key.split(':')[1]\n",
    "                    # Apply the cleaning of the addr:street \n",
    "                    if is_street_name(tag):\n",
    "                        updated_name = update_name(tag.attrib['v'],mapping)\n",
    "                        node['address'][sub_attr] = updated_name\n",
    "                    else:    \n",
    "                        node['address'][sub_attr] = value\n",
    "                # All other tags that don't begin with \"addr\"\n",
    "                elif not key.find('addr') == 0:\n",
    "                    if key not in node:\n",
    "                        node[key] = value     \n",
    "                else:\n",
    "                    node[\"tag:\" + key] = value\n",
    "\n",
    "        # Process nodes\n",
    "        for nd in element.iter('nd'):\n",
    "            if 'node_refs' not in node:\n",
    "                node['node_refs'] = []\n",
    "            node['node_refs'].append(nd.attrib['ref'])\n",
    "\n",
    "        return node\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from bson import json_util\n",
    "\n",
    "def process_map(file_in, pretty = False):\n",
    "    file_out = \"{0}.json\".format(file_in)    \n",
    "    with open(file_out, \"wb\") as fo:\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(el, indent=2, default=json_util.default)+\"\\n\")\n",
    "                else:\n",
    "                    fo.write(json.dumps(el, default=json_util.default) + \"\\n\")\n",
    "\n",
    "json_file = process_map(OSM_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from bson import json_util\n",
    "\n",
    "def process_map(file_in, pretty = False):\n",
    "    file_out = \"{0}.json\".format(file_in)    \n",
    "    with open(file_out, \"wb\") as fo:\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(el, indent=2, default=json_util.default)+\"\\n\")\n",
    "                else:\n",
    "                    fo.write(json.dumps(el, default=json_util.default) + \"\\n\")\n",
    "\n",
    "json_file = process_map(OSM_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## MangoDB  \n",
    "I'm going to import the .json which is the cleand data into mangoDB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "db_name = \"manchester_england\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# method to get database by its name: \n",
    "def get_db(db_name):\n",
    "    # For local use\n",
    "    client = MongoClient('localhost:27017')\n",
    "    db = client[db_name]\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import signal\n",
    "import subprocess\n",
    "\n",
    "pro = subprocess.Popen('mongod', preexec_fn = os.setsid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: mongoimport -h 127.0.0.1:27017 --db manchester_england --collection manchester_england_data --file /Users/hana/Desktop/datascience/manchester_england.osm.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection = 'manchester_england_data'\n",
    "working_directory = '/Users/hana/Desktop/datascience/'\n",
    "#json_file = filename + '.json'\n",
    "\n",
    "mongoimport_cmd = 'mongoimport -h 127.0.0.1:27017 ' + \\\n",
    "                  '--db ' + db_name + \\\n",
    "                  ' --collection ' + collection + \\\n",
    "                  ' --file ' + working_directory +\"manchester_england.osm.json\"\n",
    "\n",
    "# Execute the command\n",
    "print 'Executing: ' + mongoimport_cmd\n",
    "subprocess.call(mongoimport_cmd.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manchester_england_data\n"
     ]
    }
   ],
   "source": [
    "print collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database Name: manchester_england\n",
      "{u'_id': ObjectId('592ca2a2230fad747dc97875'),\n",
      " u'changeset': u'10388479',\n",
      " u'created': {u'changeset': u'10388479',\n",
      "              u'timestamp': datetime.datetime(2012, 1, 14, 14, 58, 6),\n",
      "              u'uid': u'4559',\n",
      "              u'user': u'RichardB',\n",
      "              u'version': u'2'},\n",
      " u'id': u'219434',\n",
      " u'pos': [53.3342527, -2.575179],\n",
      " u'timestamp': u'2012-01-14T14:58:06Z',\n",
      " u'type': u'node',\n",
      " u'uid': u'4559',\n",
      " u'user': u'RichardB',\n",
      " u'version': u'2'}\n"
     ]
    }
   ],
   "source": [
    "# info about the data: \n",
    "if __name__ == \"__main__\":\n",
    "    db = get_db(db_name)\n",
    "    print \"Database Name: \" + db.name\n",
    "    \n",
    "    #print \"Sample Data Point: \"\n",
    "    pprint.pprint (db.manchester_england_data.find_one())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "After getting mangodb database done , here we can get some info about it\n",
    "#### Number of ways and nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4810290\n",
      "672519\n"
     ]
    }
   ],
   "source": [
    "print db.manchester_england_data.find({\"type\": \"node\"}).count()\n",
    "print db.manchester_england_data.find({\"type\": \"way\"}).count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Number of Unique Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2133\n"
     ]
    }
   ],
   "source": [
    "print len(db.manchester_england_data.distinct(\"created.uid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def queries ():  \n",
    "    \n",
    "    print \"Top Three Contributors: \"\n",
    "    top_users = db.manchester_england_data.aggregate([{\"$group\":{\"_id\":\"$created.uid\", \"count\":{\"$sum\":1}}}, {\"$sort\":{\"count\":-1}}, {\"$limit\":3}])\n",
    "    for user in top_users:\n",
    "        print user\n",
    "    print \"=======================================================================================\"\n",
    "    print \"Top Three Amenities: \"\n",
    "    top_amenities = db.manchester_england_data.aggregate([{\"$match\":{\"amenity\":{\"$exists\":1}}}, {\"$group\":{\"_id\":\"$amenity\",\"count\":{\"$sum\":1}}}, {\"$sort\":{\"count\":-1}}, {\"$limit\":3}])\n",
    "    for amenity in top_amenities:\n",
    "        pprint.pprint(amenity)\n",
    "        \n",
    "    print \"=======================================================================================\"\n",
    "    print \"Top Three Banks: \"\n",
    "    top_banks = db.manchester_england_data.aggregate([{'$match': {'amenity': 'bank'}},{'$group': {'_id': '$name','count': {'$sum': 1}}},{'$sort': {'count': -1}},{'$limit': 3}])\n",
    "    for bank in top_banks:\n",
    "        pprint.pprint(bank)\n",
    "        \n",
    "    print \"=======================================================================================\"   \n",
    "    print \"Top Three Cities: \"\n",
    "    top_cities = db.manchester_england_data.aggregate([{'$match': {'address.city': {'$exists': 1}}},{'$group': {'_id': '$address.city', 'count': {'$sum': 1}}},{'$sort': {'count': -1}},{'$limit': 3}])\n",
    "    for city in top_cities:\n",
    "        pprint.pprint(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Three Contributors: \n",
      "{u'count': 746442, u'_id': u'4559'}\n",
      "{u'count': 288858, u'_id': u'714383'}\n",
      "{u'count': 259413, u'_id': u'101150'}\n",
      "=======================================================================================\n",
      "Top Three Amenities: \n",
      "{u'_id': u'parking', u'count': 12612}\n",
      "{u'_id': u'pub', u'count': 4686}\n",
      "{u'_id': u'school', u'count': 4056}\n",
      "=======================================================================================\n",
      "Top Three Banks: \n",
      "{u'_id': u'Barclays', u'count': 90}\n",
      "{u'_id': u'NatWest', u'count': 78}\n",
      "{u'_id': u'RBS', u'count': 72}\n",
      "=======================================================================================\n",
      "Top Three Cities: \n",
      "{u'_id': u'Manchester', u'count': 7671}\n",
      "{u'_id': u'Romiley', u'count': 2310}\n",
      "{u'_id': u'Northwich', u'count': 963}\n"
     ]
    }
   ],
   "source": [
    "queries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As we can see from the queries result , The top contributor user is '4559' , Manchecter has agreat number of parking area which is agood info for me to take into considration renting a car when i go for vacation.\n",
    "i have list the cites which is clear that not only manchecter city data is exsported from the site. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Other Ideas About the Dataset:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I am coffee addict, I would like to explore Manchester data Set and see the Following Cases:\n",
    "- Listing all the cafes \n",
    "- List the cafe shops that have outdoor earea where smoking not allowed \n",
    "- Search for Cafe North and git the address information , one of my freiend recommend it to me "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#list all the cafes in the dataset\n",
    "list_cafe = db.manchester_england_data.find({\"amenity\": \"cafe\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'changeset': u'21702777', u'amenity': u'cafe', u'uid': u'51722', u'created': {u'changeset': u'21702777', u'version': u'2', u'user': u'Chris Parker', u'timestamp': datetime.datetime(2014, 4, 15, 6, 12, 16), u'uid': u'51722'}, u'timestamp': u'2014-04-15T06:12:16Z', u'wheelchair': u'yes', u'outdoor_seating': u'yes', u'cuisine': u'coffee_shop', u'pos': [53.473716, -2.240016], u'name': u'Starbucks', u'internet_access:fee': u'no', u'version': u'2', u'user': u'Chris Parker', u'takeaway': u'yes', u'smoking': u'no', u'_id': ObjectId('592ca2b0230fad747dd2a59d'), u'type': u'node', u'id': u'1502881868', u'internet_access': u'wlan'}\n",
      "============================================================================\n",
      "{u'changeset': u'23546716', u'amenity': u'cafe', u'uid': u'51722', u'created': {u'changeset': u'23546716', u'version': u'2', u'user': u'Chris Parker', u'timestamp': datetime.datetime(2014, 7, 2, 11, 38, 25), u'uid': u'51722'}, u'timestamp': u'2014-07-02T11:38:25Z', u'wheelchair': u'limited', u'outdoor_seating': u'yes', u'pos': [53.480451, -2.244931], u'version': u'2', u'user': u'Chris Parker', u'takeaway': u'yes', u'smoking': u'no', u'_id': ObjectId('592ca2bb230fad747dd9404b'), u'type': u'node', u'id': u'2684183673', u'name': u'Caff\\xe9 Nero'}\n",
      "============================================================================\n"
     ]
    }
   ],
   "source": [
    "no_smoking = db.manchester_england_data.find({'$and':[{'outdoor_seating': 'yes'},{\"smoking\":\"no\"},{ 'amenity':'cafe'}]})\n",
    "count=0\n",
    "for c in no_smoking:\n",
    "    count+=1\n",
    "    if count ==3:\n",
    "        break\n",
    "    print c\n",
    "    print \"============================================================================\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'changeset': u'29742034', u'amenity': u'cafe', u'uid': u'5409', u'created': {u'changeset': u'29742034', u'version': u'4', u'user': u'peter_james', u'timestamp': datetime.datetime(2015, 3, 26, 0, 19, 56), u'uid': u'5409'}, u'timestamp': u'2015-03-26T00:19:56Z', u'pos': [53.4726652, -2.2395845], u'cuisine': u'coffee_shop', u'version': u'4', u'user': u'peter_james', u'address': {u'city': u'Manchester', u'street': u'Oxford Road', u'housenumber': u'14', u'postcode': u'M1 5QA'}, u'operator': u'Whitbread Group plc', u'_id': ObjectId('592ca2ab230fad747dcf09eb'), u'type': u'node', u'id': u'796761399', u'name': u'Costa'}\n",
      "============================================================================\n",
      "{u'changeset': u'29742034', u'amenity': u'cafe', u'uid': u'5409', u'created': {u'changeset': u'29742034', u'version': u'4', u'user': u'peter_james', u'timestamp': datetime.datetime(2015, 3, 26, 0, 19, 56), u'uid': u'5409'}, u'timestamp': u'2015-03-26T00:19:56Z', u'pos': [53.4726652, -2.2395845], u'cuisine': u'coffee_shop', u'version': u'4', u'user': u'peter_james', u'address': {u'city': u'Manchester', u'street': u'Oxford Road', u'housenumber': u'14', u'postcode': u'M1 5QA'}, u'operator': u'Whitbread Group plc', u'_id': ObjectId('59304bb6230fad747deb07bb'), u'type': u'node', u'id': u'796761399', u'name': u'Costa'}\n",
      "============================================================================\n",
      "{u'changeset': u'29742034', u'amenity': u'cafe', u'uid': u'5409', u'created': {u'changeset': u'29742034', u'version': u'4', u'user': u'peter_james', u'timestamp': datetime.datetime(2015, 3, 26, 0, 19, 56), u'uid': u'5409'}, u'timestamp': u'2015-03-26T00:19:56Z', u'pos': [53.4726652, -2.2395845], u'cuisine': u'coffee_shop', u'version': u'4', u'user': u'peter_james', u'address': {u'city': u'Manchester', u'street': u'Oxford Road', u'housenumber': u'14', u'postcode': u'M1 5QA'}, u'operator': u'Whitbread Group plc', u'_id': ObjectId('593485d9230fad747d071823'), u'type': u'node', u'id': u'796761399', u'name': u'Costa'}\n",
      "============================================================================\n"
     ]
    }
   ],
   "source": [
    "cafeshops = db.manchester_england_data.find({'$and':[{'address.street': 'Oxford Road'},{ 'amenity':'cafe'}]})\n",
    "for cafe in cafeshops:\n",
    "    print cafe\n",
    "    print \"============================================================================\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'changeset': u'7697865', u'amenity': u'cafe', u'uid': u'428524', u'created': {u'changeset': u'7697865', u'version': u'2', u'user': u'Daveysawyer', u'timestamp': datetime.datetime(2011, 3, 28, 15, 53, 32), u'uid': u'428524'}, u'timestamp': u'2011-03-28T15:53:32Z', u'pos': [53.4855118, -2.2370689], u'created_by': u'Potlatch 0.10f', u'name': u'Cafe North', u'version': u'2', u'user': u'Daveysawyer', u'_id': ObjectId('592ca2a7230fad747dcc8ce0'), u'type': u'node', u'id': u'357201545', u'description': u'Free wifi available for customers'}\n",
      "============================================================================\n",
      "{u'changeset': u'42000472', u'amenity': u'cafe', u'uid': u'3735060', u'created': {u'changeset': u'42000472', u'version': u'2', u'user': u'Gregory Walton', u'timestamp': datetime.datetime(2016, 9, 8, 10, 33, 26), u'uid': u'3735060'}, u'timestamp': u'2016-09-08T10:33:26Z', u'pos': [53.4752422, -2.2324674], u'version': u'2', u'user': u'Gregory Walton', u'_id': ObjectId('592ca2c2230fad747dddd58b'), u'type': u'node', u'id': u'3878522015', u'name': u'Cafe North'}\n",
      "============================================================================\n"
     ]
    }
   ],
   "source": [
    "cafes = db.manchester_england_data.find({'$and':[{'name': 'Cafe North'},{ 'amenity':'cafe'}]})\n",
    "count=0\n",
    "for cafe in cafes:\n",
    "    count+=1\n",
    "    if count ==3:\n",
    "        break\n",
    "    print cafe\n",
    "    print \"============================================================================\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings from the above invistgation :\n",
    "Only one Cafe which is Costa Cafe at Xford Street showing in the query resualt.Also Cafe North doenst have address information.This indicates that the address is not a mandatory field when the contributor enter a record.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Imporvements:\n",
    "Now we have done with cleaning parts of the data.It's importand to address the Issues of the data source and list some improvements. Considering OpenStreetMaps is an open source project and the Data entered by contributors.One of the issues I faced that there is duplication in the data which means we can find the same Cafe shope entered twice. my suggesstion for this case is that when the contributer point the location of the place there's a list nearby places appear so he knows that place is already there in the dataset.Moreover,The address or some attributes were missing or left emplty in a record/row. The solution for this case is that we enhance the validation of the text boxs.Adding restriction and validation rules will help us ensure both the accuracy ,and the correctness.\n",
    "\n",
    "There're few potential issues may be raised when implementating this solution.One of which is limiting the contributers and they will spend more time in completing one record so this may decreese the willing of contributing and entring more data.Alsoe enhancing the level of validating and showing nearby location features would be a cost since a senior of engineers with good techincal knowlege is required. \n",
    "\n",
    "In conclusion, Applying the suggestion will be a cost by requireing a dedicated team for the implementation.Also wrangling data and produce more insights without improving the data quality will need more effort and time.I belive that we can explore that data in many different ways that will produce differents outcomes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
